[04/19 17:24:43] fastreid INFO: Rank of current process: 0. World size: 1
[04/19 17:24:44] fastreid INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0]
numpy                   1.23.5
fastreid                1.3 @/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid
FASTREID_ENV_MODULE     <not set>
PyTorch                 2.0.0+cu118 @/WAVE/users2/unix/jkou/.conda/envs/aic24/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-PCIE-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  11.1.0
torchvision             0.15.1+cu118 @/WAVE/users2/unix/jkou/.conda/envs/aic24/lib/python3.9/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75, sm_80, sm_86
fvcore                  0.1.5.post20221221
cv2                     4.11.0
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/19 17:24:44] fastreid INFO: Command line arguments: Namespace(config_file='./configs/jk_experiments/agw-R101.yml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:60003', opts=[])
[04/19 17:24:44] fastreid INFO: Contents of args.config_file=./configs/jk_experiments/agw-R101.yml:
_BASE_: ../Base-AGW.yml

MODEL:
  BACKBONE:
    DEPTH: 101x


DATASETS:
  NAMES: ("AIC24",)
  TESTS: ("AIC24",)

OUTPUT_DIR:  logs/jk_experiments/agw-R101

[04/19 17:24:44] fastreid INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 8
  SAMPLER_TRAIN: NaiveIdentitySampler
  SET_WEIGHT: []
DATASETS:
  COMBINEALL: False
  NAMES: ('AIC24',)
  TESTS: ('AIC24',)
INPUT:
  AFFINE:
    ENABLED: False
  AUGMIX:
    ENABLED: False
    PROB: 0.0
  AUTOAUG:
    ENABLED: False
    PROB: 0.0
  CJ:
    BRIGHTNESS: 0.15
    CONTRAST: 0.15
    ENABLED: False
    HUE: 0.1
    PROB: 0.5
    SATURATION: 0.1
  CROP:
    ENABLED: False
    RATIO: [0.75, 1.3333333333333333]
    SCALE: [0.16, 1]
    SIZE: [224, 224]
  FLIP:
    ENABLED: True
    PROB: 0.5
  PADDING:
    ENABLED: True
    MODE: constant
    SIZE: 10
  REA:
    ENABLED: True
    PROB: 0.5
    VALUE: [123.675, 116.28, 103.53]
  RPT:
    ENABLED: False
    PROB: 0.5
  SIZE_TEST: [256, 128]
  SIZE_TRAIN: [256, 128]
KD:
  EMA:
    ENABLED: False
    MOMENTUM: 0.999
  MODEL_CONFIG: []
  MODEL_WEIGHTS: []
MODEL:
  BACKBONE:
    ATT_DROP_RATE: 0.0
    DEPTH: 101x
    DROP_PATH_RATIO: 0.1
    DROP_RATIO: 0.0
    FEAT_DIM: 2048
    LAST_STRIDE: 1
    NAME: build_resnet_backbone
    NORM: BN
    PRETRAIN: True
    PRETRAIN_PATH: 
    SIE_COE: 3.0
    STRIDE_SIZE: (16, 16)
    WITH_IBN: False
    WITH_NL: True
    WITH_SE: False
  DEVICE: cuda
  FREEZE_LAYERS: []
  HEADS:
    CLS_LAYER: Linear
    EMBEDDING_DIM: 0
    MARGIN: 0.0
    NAME: EmbeddingHead
    NECK_FEAT: before
    NORM: BN
    NUM_CLASSES: 0
    POOL_LAYER: GeneralizedMeanPooling
    SCALE: 1
    WITH_BNNECK: True
  LOSSES:
    CE:
      ALPHA: 0.2
      EPSILON: 0.1
      SCALE: 1.0
    CIRCLE:
      GAMMA: 128
      MARGIN: 0.25
      SCALE: 1.0
    COSFACE:
      GAMMA: 128
      MARGIN: 0.25
      SCALE: 1.0
    FL:
      ALPHA: 0.25
      GAMMA: 2
      SCALE: 1.0
    NAME: ('CrossEntropyLoss', 'TripletLoss')
    TRI:
      HARD_MINING: False
      MARGIN: 0.0
      NORM_FEAT: False
      SCALE: 1.0
  META_ARCHITECTURE: Baseline
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.120000000000005, 57.375]
  QUEUE_SIZE: 8192
  WEIGHTS: 
OUTPUT_DIR: logs/jk_experiments/agw-R101
SOLVER:
  AMP:
    ENABLED: True
  BASE_LR: 0.00035
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 30
  CLIP_GRADIENTS:
    CLIP_TYPE: norm
    CLIP_VALUE: 5.0
    ENABLED: False
    NORM_TYPE: 2.0
  DELAY_EPOCHS: 0
  ETA_MIN_LR: 1e-07
  FREEZE_ITERS: 0
  GAMMA: 0.1
  HEADS_LR_FACTOR: 1.0
  IMS_PER_BATCH: 64
  MAX_EPOCH: 120
  MOMENTUM: 0.9
  NESTEROV: False
  OPT: Adam
  SCHED: MultiStepLR
  STEPS: [40, 90]
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0005
  WEIGHT_DECAY_BIAS: 0.0005
  WEIGHT_DECAY_NORM: 0.0005
TEST:
  AQE:
    ALPHA: 3.0
    ENABLED: False
    QE_K: 5
    QE_TIME: 1
  EVAL_PERIOD: 30
  FLIP:
    ENABLED: False
  IMS_PER_BATCH: 128
  METRIC: cosine
  PRECISE_BN:
    DATASET: Market1501
    ENABLED: False
    NUM_ITER: 300
  RERANK:
    ENABLED: False
    K1: 20
    K2: 6
    LAMBDA: 0.3
  ROC:
    ENABLED: False
[04/19 17:24:44] fastreid INFO: Full config saved to /WAVE/users2/unix/jkou/PoseTrack/fast-reid/logs/jk_experiments/agw-R101/config.yaml
[04/19 17:24:44] fastreid.utils.env INFO: Using a generated random seed 44747889
[04/19 17:24:44] fastreid.engine.defaults INFO: Prepare training set
[04/19 17:24:44] fastreid.data.datasets.bases INFO: => Loaded AIC24 in csv format: 
| subset   | # ids   | # images   | # cameras   |
|:---------|:--------|:-----------|:------------|
| train    | 8000    | 132145     | 4           |
[04/19 17:24:44] fastreid.data.build INFO: Using training sampler NaiveIdentitySampler
[04/19 17:24:45] fastreid.engine.defaults INFO: Auto-scaling the num_classes=8000
[04/19 17:24:46] fastreid.modeling.backbones.resnet INFO: Some model parameters or buffers are not found in the checkpoint:
  NL_2.0.g.{weight, bias}
  NL_2.0.W.0.{weight, bias}
  NL_2.0.W.1.{weight, bias, running_mean, running_var}
  NL_2.0.theta.{weight, bias}
  NL_2.0.phi.{weight, bias}
  NL_2.1.g.{weight, bias}
  NL_2.1.W.0.{weight, bias}
  NL_2.1.W.1.{weight, bias, running_mean, running_var}
  NL_2.1.theta.{weight, bias}
  NL_2.1.phi.{weight, bias}
  NL_3.0.g.{weight, bias}
  NL_3.0.W.0.{weight, bias}
  NL_3.0.W.1.{weight, bias, running_mean, running_var}
  NL_3.0.theta.{weight, bias}
  NL_3.0.phi.{weight, bias}
  NL_3.1.g.{weight, bias}
  NL_3.1.W.0.{weight, bias}
  NL_3.1.W.1.{weight, bias, running_mean, running_var}
  NL_3.1.theta.{weight, bias}
  NL_3.1.phi.{weight, bias}
  NL_3.2.g.{weight, bias}
  NL_3.2.W.0.{weight, bias}
  NL_3.2.W.1.{weight, bias, running_mean, running_var}
  NL_3.2.theta.{weight, bias}
  NL_3.2.phi.{weight, bias}
  NL_3.3.g.{weight, bias}
  NL_3.3.W.0.{weight, bias}
  NL_3.3.W.1.{weight, bias, running_mean, running_var}
  NL_3.3.theta.{weight, bias}
  NL_3.3.phi.{weight, bias}
  NL_3.4.g.{weight, bias}
  NL_3.4.W.0.{weight, bias}
  NL_3.4.W.1.{weight, bias, running_mean, running_var}
  NL_3.4.theta.{weight, bias}
  NL_3.4.phi.{weight, bias}
  NL_3.5.g.{weight, bias}
  NL_3.5.W.0.{weight, bias}
  NL_3.5.W.1.{weight, bias, running_mean, running_var}
  NL_3.5.theta.{weight, bias}
  NL_3.5.phi.{weight, bias}
  NL_3.6.g.{weight, bias}
  NL_3.6.W.0.{weight, bias}
  NL_3.6.W.1.{weight, bias, running_mean, running_var}
  NL_3.6.theta.{weight, bias}
  NL_3.6.phi.{weight, bias}
  NL_3.7.g.{weight, bias}
  NL_3.7.W.0.{weight, bias}
  NL_3.7.W.1.{weight, bias, running_mean, running_var}
  NL_3.7.theta.{weight, bias}
  NL_3.7.phi.{weight, bias}
  NL_3.8.g.{weight, bias}
  NL_3.8.W.0.{weight, bias}
  NL_3.8.W.1.{weight, bias, running_mean, running_var}
  NL_3.8.theta.{weight, bias}
  NL_3.8.phi.{weight, bias}
[04/19 17:24:46] fastreid.engine.defaults INFO: Model:
Baseline(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (6): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (7): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (8): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (9): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (10): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (11): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (12): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (13): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (14): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (15): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (16): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (17): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (18): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (19): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (20): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (21): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (22): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (NL_1): ModuleList()
    (NL_2): ModuleList(
      (0-1): 2 x Non_local(
        (g): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 512, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (NL_3): ModuleList(
      (0-8): 9 x Non_local(
        (g): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 1024, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (NL_4): ModuleList()
  )
  (heads): EmbeddingHead(
    (pool_layer): GeneralizedMeanPooling(3.0, output_size=(1, 1))
    (bottleneck): Sequential(
      (0): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (cls_layer): Linear(num_classes=8000, scale=1, margin=0.0)
  )
)
[04/19 17:24:48] fastreid.utils.checkpoint INFO: No checkpoint found. Training model from scratch
[04/19 17:24:48] fastreid.engine.train_loop INFO: Starting training from epoch 0
[04/19 17:25:17] fastreid.utils.events INFO:  eta: 8:27:12  epoch/iter: 0/199  total_loss: 9.665  loss_cls: 9.022  loss_triplet: 0.6492  time: 0.1232  data_time: 0.0031  lr: 6.57e-05  max_mem: 8604M
[04/19 17:25:42] fastreid.utils.events INFO:  eta: 8:27:19  epoch/iter: 0/399  total_loss: 9.091  loss_cls: 8.841  loss_triplet: 0.2817  time: 0.1233  data_time: 0.0034  lr: 9.72e-05  max_mem: 8604M
[04/19 17:26:07] fastreid.utils.events INFO:  eta: 8:26:46  epoch/iter: 0/599  total_loss: 8.675  loss_cls: 8.511  loss_triplet: 0.1582  time: 0.1235  data_time: 0.0017  lr: 1.29e-04  max_mem: 8604M
[04/19 17:26:33] fastreid.utils.events INFO:  eta: 8:26:31  epoch/iter: 0/799  total_loss: 8.198  loss_cls: 8.089  loss_triplet: 0.1074  time: 0.1235  data_time: 0.0020  lr: 1.60e-04  max_mem: 8604M
[04/19 17:26:58] fastreid.utils.events INFO:  eta: 8:26:31  epoch/iter: 0/999  total_loss: 7.769  loss_cls: 7.665  loss_triplet: 0.08999  time: 0.1236  data_time: 0.0032  lr: 1.92e-04  max_mem: 8604M
[04/19 17:27:23] fastreid.utils.events INFO:  eta: 8:25:53  epoch/iter: 0/1199  total_loss: 7.332  loss_cls: 7.235  loss_triplet: 0.07597  time: 0.1235  data_time: 0.0029  lr: 2.23e-04  max_mem: 8604M
[04/19 17:27:48] fastreid.utils.events INFO:  eta: 8:24:05  epoch/iter: 0/1399  total_loss: 6.737  loss_cls: 6.669  loss_triplet: 0.07466  time: 0.1233  data_time: 0.0024  lr: 2.55e-04  max_mem: 8604M
[04/19 17:28:14] fastreid.utils.events INFO:  eta: 8:22:51  epoch/iter: 0/1599  total_loss: 6.151  loss_cls: 6.072  loss_triplet: 0.06918  time: 0.1231  data_time: 0.0020  lr: 2.86e-04  max_mem: 8604M
[04/19 17:28:39] fastreid.utils.events INFO:  eta: 8:21:17  epoch/iter: 0/1799  total_loss: 5.23  loss_cls: 5.147  loss_triplet: 0.06754  time: 0.1230  data_time: 0.0013  lr: 3.18e-04  max_mem: 8604M
[04/19 17:29:04] fastreid.utils.events INFO:  eta: 8:20:05  epoch/iter: 0/1999  total_loss: 4.712  loss_cls: 4.647  loss_triplet: 0.06359  time: 0.1230  data_time: 0.0042  lr: 3.49e-04  max_mem: 8604M
[04/19 17:29:12] fastreid.utils.events INFO:  eta: 8:20:33  epoch/iter: 0/2063  total_loss: 4.955  loss_cls: 4.882  loss_triplet: 0.05882  time: 0.1231  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 17:29:29] fastreid.utils.events INFO:  eta: 8:21:59  epoch/iter: 1/2199  total_loss: 4.645  loss_cls: 4.589  loss_triplet: 0.05558  time: 0.1234  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 17:29:55] fastreid.utils.events INFO:  eta: 8:26:11  epoch/iter: 1/2399  total_loss: 4.192  loss_cls: 4.142  loss_triplet: 0.05037  time: 0.1237  data_time: 0.0046  lr: 3.49e-04  max_mem: 8604M
[04/19 17:30:20] fastreid.utils.events INFO:  eta: 8:31:23  epoch/iter: 1/2599  total_loss: 3.926  loss_cls: 3.891  loss_triplet: 0.04726  time: 0.1239  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 17:30:46] fastreid.utils.events INFO:  eta: 8:36:13  epoch/iter: 1/2799  total_loss: 3.713  loss_cls: 3.662  loss_triplet: 0.04179  time: 0.1242  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 17:31:11] fastreid.utils.events INFO:  eta: 8:37:48  epoch/iter: 1/2999  total_loss: 3.521  loss_cls: 3.474  loss_triplet: 0.04168  time: 0.1244  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 17:31:36] fastreid.utils.events INFO:  eta: 8:35:32  epoch/iter: 1/3199  total_loss: 3.231  loss_cls: 3.189  loss_triplet: 0.04269  time: 0.1244  data_time: 0.0026  lr: 3.49e-04  max_mem: 8604M
[04/19 17:32:01] fastreid.utils.events INFO:  eta: 8:33:39  epoch/iter: 1/3399  total_loss: 2.993  loss_cls: 2.946  loss_triplet: 0.03969  time: 0.1245  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 17:32:27] fastreid.utils.events INFO:  eta: 8:32:34  epoch/iter: 1/3599  total_loss: 2.854  loss_cls: 2.795  loss_triplet: 0.03992  time: 0.1246  data_time: 0.0008  lr: 3.49e-04  max_mem: 8604M
[04/19 17:32:52] fastreid.utils.events INFO:  eta: 8:29:49  epoch/iter: 1/3799  total_loss: 2.38  loss_cls: 2.348  loss_triplet: 0.03684  time: 0.1247  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 17:33:17] fastreid.utils.events INFO:  eta: 8:28:22  epoch/iter: 1/3999  total_loss: 2.466  loss_cls: 2.424  loss_triplet: 0.03433  time: 0.1247  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 17:33:33] fastreid.utils.events INFO:  eta: 8:28:57  epoch/iter: 1/4127  total_loss: 2.398  loss_cls: 2.362  loss_triplet: 0.03319  time: 0.1247  data_time: 0.0026  lr: 3.49e-04  max_mem: 8604M
[04/19 17:33:42] fastreid.utils.events INFO:  eta: 8:28:26  epoch/iter: 2/4199  total_loss: 2.378  loss_cls: 2.35  loss_triplet: 0.03317  time: 0.1247  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 17:34:07] fastreid.utils.events INFO:  eta: 8:28:02  epoch/iter: 2/4399  total_loss: 2.399  loss_cls: 2.363  loss_triplet: 0.03554  time: 0.1248  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 17:34:32] fastreid.utils.events INFO:  eta: 8:26:10  epoch/iter: 2/4599  total_loss: 2.378  loss_cls: 2.343  loss_triplet: 0.02995  time: 0.1248  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 17:34:57] fastreid.utils.events INFO:  eta: 8:24:52  epoch/iter: 2/4799  total_loss: 2.315  loss_cls: 2.279  loss_triplet: 0.03205  time: 0.1247  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 17:35:22] fastreid.utils.events INFO:  eta: 8:23:34  epoch/iter: 2/4999  total_loss: 2.338  loss_cls: 2.295  loss_triplet: 0.03206  time: 0.1247  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 17:35:47] fastreid.utils.events INFO:  eta: 8:22:40  epoch/iter: 2/5199  total_loss: 2.326  loss_cls: 2.296  loss_triplet: 0.02984  time: 0.1247  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 17:36:12] fastreid.utils.events INFO:  eta: 8:22:16  epoch/iter: 2/5399  total_loss: 2.235  loss_cls: 2.2  loss_triplet: 0.02939  time: 0.1248  data_time: 0.0012  lr: 3.49e-04  max_mem: 8604M
[04/19 17:36:37] fastreid.utils.events INFO:  eta: 8:22:52  epoch/iter: 2/5599  total_loss: 2.085  loss_cls: 2.046  loss_triplet: 0.03048  time: 0.1248  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 17:37:02] fastreid.utils.events INFO:  eta: 8:24:57  epoch/iter: 2/5799  total_loss: 2.147  loss_cls: 2.115  loss_triplet: 0.02968  time: 0.1249  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 17:37:28] fastreid.utils.events INFO:  eta: 8:26:23  epoch/iter: 2/5999  total_loss: 2.172  loss_cls: 2.147  loss_triplet: 0.02526  time: 0.1249  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 17:37:52] fastreid.utils.events INFO:  eta: 8:27:41  epoch/iter: 2/6191  total_loss: 2.156  loss_cls: 2.134  loss_triplet: 0.02672  time: 0.1250  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 17:37:53] fastreid.utils.events INFO:  eta: 8:27:38  epoch/iter: 3/6199  total_loss: 2.165  loss_cls: 2.142  loss_triplet: 0.02712  time: 0.1250  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 17:38:18] fastreid.utils.events INFO:  eta: 8:28:27  epoch/iter: 3/6399  total_loss: 2.198  loss_cls: 2.161  loss_triplet: 0.02809  time: 0.1250  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 17:38:44] fastreid.utils.events INFO:  eta: 8:28:27  epoch/iter: 3/6599  total_loss: 2.173  loss_cls: 2.138  loss_triplet: 0.02744  time: 0.1251  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 17:39:09] fastreid.utils.events INFO:  eta: 8:27:51  epoch/iter: 3/6799  total_loss: 2.219  loss_cls: 2.181  loss_triplet: 0.02702  time: 0.1251  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 17:39:34] fastreid.utils.events INFO:  eta: 8:27:00  epoch/iter: 3/6999  total_loss: 2.211  loss_cls: 2.185  loss_triplet: 0.02746  time: 0.1252  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 17:40:00] fastreid.utils.events INFO:  eta: 8:25:49  epoch/iter: 3/7199  total_loss: 2.157  loss_cls: 2.126  loss_triplet: 0.02635  time: 0.1252  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 17:40:25] fastreid.utils.events INFO:  eta: 8:24:14  epoch/iter: 3/7399  total_loss: 2.053  loss_cls: 2.027  loss_triplet: 0.0271  time: 0.1252  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 17:40:50] fastreid.utils.events INFO:  eta: 8:23:25  epoch/iter: 3/7599  total_loss: 1.967  loss_cls: 1.94  loss_triplet: 0.02626  time: 0.1252  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 17:41:15] fastreid.utils.events INFO:  eta: 8:22:46  epoch/iter: 3/7799  total_loss: 2.125  loss_cls: 2.098  loss_triplet: 0.02454  time: 0.1252  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 17:41:40] fastreid.utils.events INFO:  eta: 8:21:36  epoch/iter: 3/7999  total_loss: 2.114  loss_cls: 2.08  loss_triplet: 0.02518  time: 0.1252  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 17:42:05] fastreid.utils.events INFO:  eta: 8:20:35  epoch/iter: 3/8199  total_loss: 2.122  loss_cls: 2.093  loss_triplet: 0.02646  time: 0.1252  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 17:42:12] fastreid.utils.events INFO:  eta: 8:20:34  epoch/iter: 3/8255  total_loss: 2.143  loss_cls: 2.116  loss_triplet: 0.02525  time: 0.1252  data_time: 0.0026  lr: 3.49e-04  max_mem: 8604M
[04/19 17:42:30] fastreid.utils.events INFO:  eta: 8:19:59  epoch/iter: 4/8399  total_loss: 2.125  loss_cls: 2.101  loss_triplet: 0.02219  time: 0.1252  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 17:42:55] fastreid.utils.events INFO:  eta: 8:19:08  epoch/iter: 4/8599  total_loss: 2.158  loss_cls: 2.124  loss_triplet: 0.02418  time: 0.1252  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 17:43:20] fastreid.utils.events INFO:  eta: 8:17:23  epoch/iter: 4/8799  total_loss: 2.123  loss_cls: 2.085  loss_triplet: 0.02248  time: 0.1252  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 17:43:45] fastreid.utils.events INFO:  eta: 8:16:58  epoch/iter: 4/8999  total_loss: 2.135  loss_cls: 2.111  loss_triplet: 0.02649  time: 0.1252  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 17:44:10] fastreid.utils.events INFO:  eta: 8:16:58  epoch/iter: 4/9199  total_loss: 2.09  loss_cls: 2.062  loss_triplet: 0.02508  time: 0.1252  data_time: 0.0009  lr: 3.49e-04  max_mem: 8604M
[04/19 17:44:36] fastreid.utils.events INFO:  eta: 8:16:41  epoch/iter: 4/9399  total_loss: 1.927  loss_cls: 1.895  loss_triplet: 0.02299  time: 0.1252  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 17:45:01] fastreid.utils.events INFO:  eta: 8:17:27  epoch/iter: 4/9599  total_loss: 2.002  loss_cls: 1.987  loss_triplet: 0.0207  time: 0.1253  data_time: 0.0030  lr: 3.49e-04  max_mem: 8604M
[04/19 17:45:26] fastreid.utils.events INFO:  eta: 8:18:07  epoch/iter: 4/9799  total_loss: 2.048  loss_cls: 2.03  loss_triplet: 0.01954  time: 0.1253  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 17:45:51] fastreid.utils.events INFO:  eta: 8:17:47  epoch/iter: 4/9999  total_loss: 2.038  loss_cls: 2.017  loss_triplet: 0.01931  time: 0.1253  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 17:46:17] fastreid.utils.events INFO:  eta: 8:17:48  epoch/iter: 4/10199  total_loss: 2.038  loss_cls: 2.022  loss_triplet: 0.02368  time: 0.1253  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 17:46:32] fastreid.utils.events INFO:  eta: 8:18:42  epoch/iter: 4/10319  total_loss: 2.066  loss_cls: 2.038  loss_triplet: 0.02259  time: 0.1253  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 17:46:42] fastreid.utils.events INFO:  eta: 8:18:26  epoch/iter: 5/10399  total_loss: 2.055  loss_cls: 2.032  loss_triplet: 0.02084  time: 0.1253  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 17:47:07] fastreid.utils.events INFO:  eta: 8:16:58  epoch/iter: 5/10599  total_loss: 2.073  loss_cls: 2.041  loss_triplet: 0.02221  time: 0.1253  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 17:47:32] fastreid.utils.events INFO:  eta: 8:16:33  epoch/iter: 5/10799  total_loss: 2.072  loss_cls: 2.052  loss_triplet: 0.02038  time: 0.1254  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 17:47:58] fastreid.utils.events INFO:  eta: 8:16:00  epoch/iter: 5/10999  total_loss: 2.07  loss_cls: 2.051  loss_triplet: 0.02175  time: 0.1254  data_time: 0.0012  lr: 3.49e-04  max_mem: 8604M
[04/19 17:48:23] fastreid.utils.events INFO:  eta: 8:14:36  epoch/iter: 5/11199  total_loss: 1.945  loss_cls: 1.917  loss_triplet: 0.02215  time: 0.1254  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 17:48:48] fastreid.utils.events INFO:  eta: 8:14:14  epoch/iter: 5/11399  total_loss: 1.891  loss_cls: 1.856  loss_triplet: 0.02356  time: 0.1254  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 17:49:14] fastreid.utils.events INFO:  eta: 8:15:26  epoch/iter: 5/11599  total_loss: 1.992  loss_cls: 1.968  loss_triplet: 0.02035  time: 0.1254  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 17:49:39] fastreid.utils.events INFO:  eta: 8:15:47  epoch/iter: 5/11799  total_loss: 2.015  loss_cls: 1.999  loss_triplet: 0.02042  time: 0.1255  data_time: 0.0038  lr: 3.49e-04  max_mem: 8604M
[04/19 17:50:04] fastreid.utils.events INFO:  eta: 8:16:39  epoch/iter: 5/11999  total_loss: 1.998  loss_cls: 1.978  loss_triplet: 0.02139  time: 0.1255  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 17:50:30] fastreid.utils.events INFO:  eta: 8:17:26  epoch/iter: 5/12199  total_loss: 2.03  loss_cls: 2.008  loss_triplet: 0.01971  time: 0.1255  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 17:50:53] fastreid.utils.events INFO:  eta: 8:17:56  epoch/iter: 5/12383  total_loss: 2.006  loss_cls: 1.993  loss_triplet: 0.01994  time: 0.1255  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 17:50:55] fastreid.utils.events INFO:  eta: 8:17:52  epoch/iter: 6/12399  total_loss: 1.982  loss_cls: 1.954  loss_triplet: 0.01942  time: 0.1256  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 17:51:21] fastreid.utils.events INFO:  eta: 8:17:01  epoch/iter: 6/12599  total_loss: 2.013  loss_cls: 1.981  loss_triplet: 0.02256  time: 0.1256  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 17:51:46] fastreid.utils.events INFO:  eta: 8:16:18  epoch/iter: 6/12799  total_loss: 1.991  loss_cls: 1.967  loss_triplet: 0.02032  time: 0.1256  data_time: 0.0026  lr: 3.49e-04  max_mem: 8604M
[04/19 17:52:11] fastreid.utils.events INFO:  eta: 8:15:10  epoch/iter: 6/12999  total_loss: 1.94  loss_cls: 1.915  loss_triplet: 0.01928  time: 0.1256  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 17:52:37] fastreid.utils.events INFO:  eta: 8:14:09  epoch/iter: 6/13199  total_loss: 1.773  loss_cls: 1.754  loss_triplet: 0.02053  time: 0.1256  data_time: 0.0039  lr: 3.49e-04  max_mem: 8604M
[04/19 17:53:02] fastreid.utils.events INFO:  eta: 8:13:16  epoch/iter: 6/13399  total_loss: 1.952  loss_cls: 1.932  loss_triplet: 0.0182  time: 0.1256  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 17:53:28] fastreid.utils.events INFO:  eta: 8:12:33  epoch/iter: 6/13599  total_loss: 1.966  loss_cls: 1.947  loss_triplet: 0.01876  time: 0.1257  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 17:53:53] fastreid.utils.events INFO:  eta: 8:12:25  epoch/iter: 6/13799  total_loss: 1.957  loss_cls: 1.939  loss_triplet: 0.01957  time: 0.1257  data_time: 0.0030  lr: 3.49e-04  max_mem: 8604M
[04/19 17:54:18] fastreid.utils.events INFO:  eta: 8:13:09  epoch/iter: 6/13999  total_loss: 1.982  loss_cls: 1.954  loss_triplet: 0.02088  time: 0.1257  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 17:54:44] fastreid.utils.events INFO:  eta: 8:12:40  epoch/iter: 6/14199  total_loss: 1.938  loss_cls: 1.918  loss_triplet: 0.02023  time: 0.1257  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 17:55:09] fastreid.utils.events INFO:  eta: 8:11:42  epoch/iter: 6/14399  total_loss: 1.98  loss_cls: 1.956  loss_triplet: 0.02046  time: 0.1257  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 17:55:15] fastreid.utils.events INFO:  eta: 8:11:36  epoch/iter: 6/14447  total_loss: 1.985  loss_cls: 1.96  loss_triplet: 0.02129  time: 0.1257  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 17:55:34] fastreid.utils.events INFO:  eta: 8:10:59  epoch/iter: 7/14599  total_loss: 1.95  loss_cls: 1.927  loss_triplet: 0.02036  time: 0.1257  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 17:56:00] fastreid.utils.events INFO:  eta: 8:10:24  epoch/iter: 7/14799  total_loss: 1.93  loss_cls: 1.904  loss_triplet: 0.01744  time: 0.1257  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 17:56:25] fastreid.utils.events INFO:  eta: 8:08:29  epoch/iter: 7/14999  total_loss: 1.84  loss_cls: 1.818  loss_triplet: 0.01966  time: 0.1257  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 17:56:50] fastreid.utils.events INFO:  eta: 8:08:07  epoch/iter: 7/15199  total_loss: 1.815  loss_cls: 1.797  loss_triplet: 0.02002  time: 0.1257  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 17:57:16] fastreid.utils.events INFO:  eta: 8:07:52  epoch/iter: 7/15399  total_loss: 1.884  loss_cls: 1.859  loss_triplet: 0.01699  time: 0.1258  data_time: 0.0037  lr: 3.49e-04  max_mem: 8604M
[04/19 17:57:41] fastreid.utils.events INFO:  eta: 8:07:44  epoch/iter: 7/15599  total_loss: 1.911  loss_cls: 1.894  loss_triplet: 0.01776  time: 0.1258  data_time: 0.0036  lr: 3.49e-04  max_mem: 8604M
[04/19 17:58:06] fastreid.utils.events INFO:  eta: 8:07:22  epoch/iter: 7/15799  total_loss: 1.925  loss_cls: 1.907  loss_triplet: 0.01734  time: 0.1258  data_time: 0.0036  lr: 3.49e-04  max_mem: 8604M
[04/19 17:58:32] fastreid.utils.events INFO:  eta: 8:08:08  epoch/iter: 7/15999  total_loss: 1.963  loss_cls: 1.941  loss_triplet: 0.01868  time: 0.1258  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 17:58:57] fastreid.utils.events INFO:  eta: 8:07:54  epoch/iter: 7/16199  total_loss: 1.946  loss_cls: 1.924  loss_triplet: 0.01813  time: 0.1258  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 17:59:22] fastreid.utils.events INFO:  eta: 8:06:29  epoch/iter: 7/16399  total_loss: 1.938  loss_cls: 1.916  loss_triplet: 0.01784  time: 0.1258  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 17:59:36] fastreid.utils.events INFO:  eta: 8:05:30  epoch/iter: 7/16511  total_loss: 1.938  loss_cls: 1.905  loss_triplet: 0.01819  time: 0.1258  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 17:59:47] fastreid.utils.events INFO:  eta: 8:05:13  epoch/iter: 8/16599  total_loss: 1.923  loss_cls: 1.892  loss_triplet: 0.01816  time: 0.1258  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 18:00:12] fastreid.utils.events INFO:  eta: 8:03:53  epoch/iter: 8/16799  total_loss: 1.879  loss_cls: 1.862  loss_triplet: 0.01829  time: 0.1258  data_time: 0.0015  lr: 3.49e-04  max_mem: 8604M
[04/19 18:00:38] fastreid.utils.events INFO:  eta: 8:02:48  epoch/iter: 8/16999  total_loss: 1.741  loss_cls: 1.717  loss_triplet: 0.01837  time: 0.1258  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 18:01:03] fastreid.utils.events INFO:  eta: 8:02:42  epoch/iter: 8/17199  total_loss: 1.875  loss_cls: 1.857  loss_triplet: 0.01646  time: 0.1258  data_time: 0.0036  lr: 3.49e-04  max_mem: 8604M
[04/19 18:01:28] fastreid.utils.events INFO:  eta: 8:03:18  epoch/iter: 8/17399  total_loss: 1.866  loss_cls: 1.844  loss_triplet: 0.01626  time: 0.1258  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 18:01:54] fastreid.utils.events INFO:  eta: 8:03:46  epoch/iter: 8/17599  total_loss: 1.888  loss_cls: 1.868  loss_triplet: 0.01729  time: 0.1258  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 18:02:19] fastreid.utils.events INFO:  eta: 8:04:16  epoch/iter: 8/17799  total_loss: 1.947  loss_cls: 1.925  loss_triplet: 0.01792  time: 0.1258  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 18:02:44] fastreid.utils.events INFO:  eta: 8:04:35  epoch/iter: 8/17999  total_loss: 1.916  loss_cls: 1.89  loss_triplet: 0.01863  time: 0.1258  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 18:03:09] fastreid.utils.events INFO:  eta: 8:03:53  epoch/iter: 8/18199  total_loss: 1.945  loss_cls: 1.914  loss_triplet: 0.01825  time: 0.1259  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 18:03:35] fastreid.utils.events INFO:  eta: 8:02:42  epoch/iter: 8/18399  total_loss: 1.899  loss_cls: 1.881  loss_triplet: 0.01737  time: 0.1259  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 18:03:57] fastreid.utils.events INFO:  eta: 8:01:42  epoch/iter: 8/18575  total_loss: 1.903  loss_cls: 1.878  loss_triplet: 0.01729  time: 0.1259  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 18:04:00] fastreid.utils.events INFO:  eta: 8:01:24  epoch/iter: 9/18599  total_loss: 1.916  loss_cls: 1.9  loss_triplet: 0.01771  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:04:25] fastreid.utils.events INFO:  eta: 7:59:21  epoch/iter: 9/18799  total_loss: 1.777  loss_cls: 1.76  loss_triplet: 0.01911  time: 0.1258  data_time: 0.0010  lr: 3.49e-04  max_mem: 8604M
[04/19 18:04:50] fastreid.utils.events INFO:  eta: 7:58:55  epoch/iter: 9/18999  total_loss: 1.798  loss_cls: 1.783  loss_triplet: 0.01563  time: 0.1258  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 18:05:15] fastreid.utils.events INFO:  eta: 7:58:07  epoch/iter: 9/19199  total_loss: 1.877  loss_cls: 1.861  loss_triplet: 0.01634  time: 0.1258  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 18:05:40] fastreid.utils.events INFO:  eta: 7:57:56  epoch/iter: 9/19399  total_loss: 1.905  loss_cls: 1.892  loss_triplet: 0.01628  time: 0.1258  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 18:06:06] fastreid.utils.events INFO:  eta: 7:58:20  epoch/iter: 9/19599  total_loss: 1.883  loss_cls: 1.862  loss_triplet: 0.01745  time: 0.1259  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 18:06:31] fastreid.utils.events INFO:  eta: 7:59:35  epoch/iter: 9/19799  total_loss: 1.853  loss_cls: 1.833  loss_triplet: 0.0175  time: 0.1259  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 18:06:56] fastreid.utils.events INFO:  eta: 7:58:58  epoch/iter: 9/19999  total_loss: 1.89  loss_cls: 1.869  loss_triplet: 0.01842  time: 0.1259  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:07:21] fastreid.utils.events INFO:  eta: 7:57:59  epoch/iter: 9/20199  total_loss: 1.899  loss_cls: 1.884  loss_triplet: 0.01767  time: 0.1259  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 18:07:46] fastreid.utils.events INFO:  eta: 7:56:16  epoch/iter: 9/20399  total_loss: 1.848  loss_cls: 1.822  loss_triplet: 0.01744  time: 0.1259  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 18:08:11] fastreid.utils.events INFO:  eta: 7:54:34  epoch/iter: 9/20599  total_loss: 1.808  loss_cls: 1.784  loss_triplet: 0.01807  time: 0.1258  data_time: 0.0009  lr: 3.49e-04  max_mem: 8604M
[04/19 18:08:16] fastreid.utils.events INFO:  eta: 7:54:19  epoch/iter: 9/20639  total_loss: 1.796  loss_cls: 1.774  loss_triplet: 0.01807  time: 0.1258  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:08:37] fastreid.utils.events INFO:  eta: 7:53:04  epoch/iter: 10/20799  total_loss: 1.762  loss_cls: 1.74  loss_triplet: 0.02002  time: 0.1258  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 18:09:02] fastreid.utils.events INFO:  eta: 7:51:59  epoch/iter: 10/20999  total_loss: 1.865  loss_cls: 1.845  loss_triplet: 0.01569  time: 0.1258  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:09:27] fastreid.utils.events INFO:  eta: 7:51:36  epoch/iter: 10/21199  total_loss: 1.841  loss_cls: 1.825  loss_triplet: 0.01567  time: 0.1258  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 18:09:52] fastreid.utils.events INFO:  eta: 7:52:00  epoch/iter: 10/21399  total_loss: 1.847  loss_cls: 1.825  loss_triplet: 0.018  time: 0.1258  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 18:10:17] fastreid.utils.events INFO:  eta: 7:51:39  epoch/iter: 10/21599  total_loss: 1.88  loss_cls: 1.86  loss_triplet: 0.01662  time: 0.1258  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 18:10:42] fastreid.utils.events INFO:  eta: 7:51:09  epoch/iter: 10/21799  total_loss: 1.844  loss_cls: 1.817  loss_triplet: 0.0167  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:11:07] fastreid.utils.events INFO:  eta: 7:50:22  epoch/iter: 10/21999  total_loss: 1.856  loss_cls: 1.833  loss_triplet: 0.01586  time: 0.1258  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 18:11:32] fastreid.utils.events INFO:  eta: 7:50:57  epoch/iter: 10/22199  total_loss: 1.848  loss_cls: 1.832  loss_triplet: 0.01569  time: 0.1258  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 18:11:57] fastreid.utils.events INFO:  eta: 7:49:09  epoch/iter: 10/22399  total_loss: 1.861  loss_cls: 1.836  loss_triplet: 0.01726  time: 0.1258  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 18:12:22] fastreid.utils.events INFO:  eta: 7:48:54  epoch/iter: 10/22599  total_loss: 1.738  loss_cls: 1.719  loss_triplet: 0.01889  time: 0.1258  data_time: 0.0010  lr: 3.49e-04  max_mem: 8604M
[04/19 18:12:35] fastreid.utils.events INFO:  eta: 7:48:52  epoch/iter: 10/22703  total_loss: 1.734  loss_cls: 1.704  loss_triplet: 0.01795  time: 0.1258  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 18:12:47] fastreid.utils.events INFO:  eta: 7:49:14  epoch/iter: 11/22799  total_loss: 1.792  loss_cls: 1.768  loss_triplet: 0.01624  time: 0.1258  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 18:13:13] fastreid.utils.events INFO:  eta: 7:49:30  epoch/iter: 11/22999  total_loss: 1.817  loss_cls: 1.8  loss_triplet: 0.01482  time: 0.1258  data_time: 0.0037  lr: 3.49e-04  max_mem: 8604M
[04/19 18:13:38] fastreid.utils.events INFO:  eta: 7:48:54  epoch/iter: 11/23199  total_loss: 1.818  loss_cls: 1.802  loss_triplet: 0.01368  time: 0.1258  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 18:14:03] fastreid.utils.events INFO:  eta: 7:49:10  epoch/iter: 11/23399  total_loss: 1.833  loss_cls: 1.807  loss_triplet: 0.01589  time: 0.1258  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 18:14:28] fastreid.utils.events INFO:  eta: 7:50:12  epoch/iter: 11/23599  total_loss: 1.851  loss_cls: 1.825  loss_triplet: 0.0172  time: 0.1258  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 18:14:54] fastreid.utils.events INFO:  eta: 7:49:30  epoch/iter: 11/23799  total_loss: 1.853  loss_cls: 1.835  loss_triplet: 0.01532  time: 0.1258  data_time: 0.0015  lr: 3.49e-04  max_mem: 8604M
[04/19 18:15:19] fastreid.utils.events INFO:  eta: 7:48:34  epoch/iter: 11/23999  total_loss: 1.876  loss_cls: 1.854  loss_triplet: 0.01802  time: 0.1258  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 18:15:44] fastreid.utils.events INFO:  eta: 7:47:45  epoch/iter: 11/24199  total_loss: 1.836  loss_cls: 1.816  loss_triplet: 0.01654  time: 0.1258  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:16:09] fastreid.utils.events INFO:  eta: 7:46:51  epoch/iter: 11/24399  total_loss: 1.779  loss_cls: 1.755  loss_triplet: 0.01862  time: 0.1258  data_time: 0.0010  lr: 3.49e-04  max_mem: 8604M
[04/19 18:16:34] fastreid.utils.events INFO:  eta: 7:45:16  epoch/iter: 11/24599  total_loss: 1.739  loss_cls: 1.714  loss_triplet: 0.01827  time: 0.1258  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 18:16:55] fastreid.utils.events INFO:  eta: 7:44:33  epoch/iter: 11/24767  total_loss: 1.808  loss_cls: 1.789  loss_triplet: 0.01587  time: 0.1258  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 18:16:59] fastreid.utils.events INFO:  eta: 7:44:39  epoch/iter: 12/24799  total_loss: 1.812  loss_cls: 1.792  loss_triplet: 0.0149  time: 0.1258  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 18:17:24] fastreid.utils.events INFO:  eta: 7:43:47  epoch/iter: 12/24999  total_loss: 1.794  loss_cls: 1.774  loss_triplet: 0.01493  time: 0.1258  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 18:17:49] fastreid.utils.events INFO:  eta: 7:43:38  epoch/iter: 12/25199  total_loss: 1.836  loss_cls: 1.82  loss_triplet: 0.01688  time: 0.1258  data_time: 0.0041  lr: 3.49e-04  max_mem: 8604M
[04/19 18:18:15] fastreid.utils.events INFO:  eta: 7:44:31  epoch/iter: 12/25399  total_loss: 1.829  loss_cls: 1.811  loss_triplet: 0.01406  time: 0.1258  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 18:18:40] fastreid.utils.events INFO:  eta: 7:44:55  epoch/iter: 12/25599  total_loss: 1.821  loss_cls: 1.803  loss_triplet: 0.01753  time: 0.1258  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 18:19:05] fastreid.utils.events INFO:  eta: 7:44:57  epoch/iter: 12/25799  total_loss: 1.857  loss_cls: 1.835  loss_triplet: 0.0159  time: 0.1258  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:19:30] fastreid.utils.events INFO:  eta: 7:45:00  epoch/iter: 12/25999  total_loss: 1.83  loss_cls: 1.809  loss_triplet: 0.01696  time: 0.1258  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:19:56] fastreid.utils.events INFO:  eta: 7:44:45  epoch/iter: 12/26199  total_loss: 1.789  loss_cls: 1.773  loss_triplet: 0.01569  time: 0.1258  data_time: 0.0015  lr: 3.49e-04  max_mem: 8604M
[04/19 18:20:21] fastreid.utils.events INFO:  eta: 7:43:46  epoch/iter: 12/26399  total_loss: 1.662  loss_cls: 1.642  loss_triplet: 0.01576  time: 0.1258  data_time: 0.0010  lr: 3.49e-04  max_mem: 8604M
[04/19 18:20:46] fastreid.utils.events INFO:  eta: 7:43:53  epoch/iter: 12/26599  total_loss: 1.792  loss_cls: 1.771  loss_triplet: 0.01639  time: 0.1258  data_time: 0.0037  lr: 3.49e-04  max_mem: 8604M
[04/19 18:21:11] fastreid.utils.events INFO:  eta: 7:43:51  epoch/iter: 12/26799  total_loss: 1.794  loss_cls: 1.776  loss_triplet: 0.01511  time: 0.1258  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 18:21:16] fastreid.utils.events INFO:  eta: 7:43:56  epoch/iter: 12/26831  total_loss: 1.791  loss_cls: 1.775  loss_triplet: 0.01571  time: 0.1258  data_time: 0.0030  lr: 3.49e-04  max_mem: 8604M
[04/19 18:21:37] fastreid.utils.events INFO:  eta: 7:43:48  epoch/iter: 13/26999  total_loss: 1.805  loss_cls: 1.784  loss_triplet: 0.01568  time: 0.1258  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 18:22:02] fastreid.utils.events INFO:  eta: 7:43:53  epoch/iter: 13/27199  total_loss: 1.793  loss_cls: 1.782  loss_triplet: 0.01567  time: 0.1258  data_time: 0.0029  lr: 3.49e-04  max_mem: 8604M
[04/19 18:22:28] fastreid.utils.events INFO:  eta: 7:45:20  epoch/iter: 13/27399  total_loss: 1.798  loss_cls: 1.785  loss_triplet: 0.01598  time: 0.1259  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:22:53] fastreid.utils.events INFO:  eta: 7:45:15  epoch/iter: 13/27599  total_loss: 1.85  loss_cls: 1.825  loss_triplet: 0.01546  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 18:23:19] fastreid.utils.events INFO:  eta: 7:44:30  epoch/iter: 13/27799  total_loss: 1.812  loss_cls: 1.795  loss_triplet: 0.01594  time: 0.1259  data_time: 0.0030  lr: 3.49e-04  max_mem: 8604M
[04/19 18:23:44] fastreid.utils.events INFO:  eta: 7:44:08  epoch/iter: 13/27999  total_loss: 1.812  loss_cls: 1.793  loss_triplet: 0.01511  time: 0.1259  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 18:24:09] fastreid.utils.events INFO:  eta: 7:43:19  epoch/iter: 13/28199  total_loss: 1.717  loss_cls: 1.699  loss_triplet: 0.01653  time: 0.1259  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 18:24:35] fastreid.utils.events INFO:  eta: 7:41:45  epoch/iter: 13/28399  total_loss: 1.698  loss_cls: 1.684  loss_triplet: 0.01509  time: 0.1259  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 18:25:00] fastreid.utils.events INFO:  eta: 7:39:54  epoch/iter: 13/28599  total_loss: 1.768  loss_cls: 1.751  loss_triplet: 0.01413  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:25:25] fastreid.utils.events INFO:  eta: 7:38:39  epoch/iter: 13/28799  total_loss: 1.78  loss_cls: 1.766  loss_triplet: 0.01619  time: 0.1259  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 18:25:37] fastreid.utils.events INFO:  eta: 7:37:36  epoch/iter: 13/28895  total_loss: 1.776  loss_cls: 1.756  loss_triplet: 0.01549  time: 0.1259  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 18:25:50] fastreid.utils.events INFO:  eta: 7:37:20  epoch/iter: 14/28999  total_loss: 1.799  loss_cls: 1.769  loss_triplet: 0.01555  time: 0.1259  data_time: 0.0039  lr: 3.49e-04  max_mem: 8604M
[04/19 18:26:15] fastreid.utils.events INFO:  eta: 7:36:26  epoch/iter: 14/29199  total_loss: 1.827  loss_cls: 1.8  loss_triplet: 0.01642  time: 0.1259  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 18:26:40] fastreid.utils.events INFO:  eta: 7:35:16  epoch/iter: 14/29399  total_loss: 1.838  loss_cls: 1.819  loss_triplet: 0.0149  time: 0.1259  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 18:27:05] fastreid.utils.events INFO:  eta: 7:35:04  epoch/iter: 14/29599  total_loss: 1.805  loss_cls: 1.783  loss_triplet: 0.01605  time: 0.1259  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 18:27:30] fastreid.utils.events INFO:  eta: 7:34:56  epoch/iter: 14/29799  total_loss: 1.806  loss_cls: 1.785  loss_triplet: 0.01476  time: 0.1259  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 18:27:55] fastreid.utils.events INFO:  eta: 7:34:06  epoch/iter: 14/29999  total_loss: 1.782  loss_cls: 1.764  loss_triplet: 0.01528  time: 0.1259  data_time: 0.0010  lr: 3.49e-04  max_mem: 8604M
[04/19 18:28:20] fastreid.utils.events INFO:  eta: 7:32:25  epoch/iter: 14/30199  total_loss: 1.674  loss_cls: 1.657  loss_triplet: 0.01656  time: 0.1258  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:28:45] fastreid.utils.events INFO:  eta: 7:31:04  epoch/iter: 14/30399  total_loss: 1.756  loss_cls: 1.74  loss_triplet: 0.01351  time: 0.1258  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:29:10] fastreid.utils.events INFO:  eta: 7:30:12  epoch/iter: 14/30599  total_loss: 1.775  loss_cls: 1.756  loss_triplet: 0.01358  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:29:35] fastreid.utils.events INFO:  eta: 7:29:08  epoch/iter: 14/30799  total_loss: 1.823  loss_cls: 1.806  loss_triplet: 0.01623  time: 0.1258  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:29:55] fastreid.utils.events INFO:  eta: 7:28:42  epoch/iter: 14/30959  total_loss: 1.773  loss_cls: 1.757  loss_triplet: 0.01333  time: 0.1258  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 18:30:00] fastreid.utils.events INFO:  eta: 7:28:44  epoch/iter: 15/30999  total_loss: 1.771  loss_cls: 1.752  loss_triplet: 0.01314  time: 0.1258  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 18:30:25] fastreid.utils.events INFO:  eta: 7:29:03  epoch/iter: 15/31199  total_loss: 1.804  loss_cls: 1.787  loss_triplet: 0.01522  time: 0.1258  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:30:51] fastreid.utils.events INFO:  eta: 7:30:54  epoch/iter: 15/31399  total_loss: 1.779  loss_cls: 1.755  loss_triplet: 0.0148  time: 0.1258  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 18:31:16] fastreid.utils.events INFO:  eta: 7:32:13  epoch/iter: 15/31599  total_loss: 1.829  loss_cls: 1.809  loss_triplet: 0.01607  time: 0.1258  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 18:31:41] fastreid.utils.events INFO:  eta: 7:32:23  epoch/iter: 15/31799  total_loss: 1.796  loss_cls: 1.769  loss_triplet: 0.01751  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:32:06] fastreid.utils.events INFO:  eta: 7:32:02  epoch/iter: 15/31999  total_loss: 1.7  loss_cls: 1.682  loss_triplet: 0.01625  time: 0.1258  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 18:32:32] fastreid.utils.events INFO:  eta: 7:32:55  epoch/iter: 15/32199  total_loss: 1.727  loss_cls: 1.708  loss_triplet: 0.01633  time: 0.1258  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 18:32:57] fastreid.utils.events INFO:  eta: 7:32:13  epoch/iter: 15/32399  total_loss: 1.732  loss_cls: 1.717  loss_triplet: 0.01436  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:33:22] fastreid.utils.events INFO:  eta: 7:31:35  epoch/iter: 15/32599  total_loss: 1.787  loss_cls: 1.769  loss_triplet: 0.01514  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:33:48] fastreid.utils.events INFO:  eta: 7:31:36  epoch/iter: 15/32799  total_loss: 1.783  loss_cls: 1.769  loss_triplet: 0.01516  time: 0.1258  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:34:13] fastreid.utils.events INFO:  eta: 7:31:11  epoch/iter: 15/32999  total_loss: 1.784  loss_cls: 1.766  loss_triplet: 0.01367  time: 0.1258  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 18:34:16] fastreid.utils.events INFO:  eta: 7:31:08  epoch/iter: 15/33023  total_loss: 1.789  loss_cls: 1.775  loss_triplet: 0.01354  time: 0.1258  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:34:38] fastreid.utils.events INFO:  eta: 7:30:01  epoch/iter: 16/33199  total_loss: 1.803  loss_cls: 1.789  loss_triplet: 0.0147  time: 0.1258  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 18:35:03] fastreid.utils.events INFO:  eta: 7:29:19  epoch/iter: 16/33399  total_loss: 1.814  loss_cls: 1.795  loss_triplet: 0.01692  time: 0.1258  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 18:35:28] fastreid.utils.events INFO:  eta: 7:27:20  epoch/iter: 16/33599  total_loss: 1.781  loss_cls: 1.756  loss_triplet: 0.0156  time: 0.1258  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 18:35:53] fastreid.utils.events INFO:  eta: 7:25:16  epoch/iter: 16/33799  total_loss: 1.746  loss_cls: 1.724  loss_triplet: 0.0157  time: 0.1258  data_time: 0.0007  lr: 3.49e-04  max_mem: 8604M
[04/19 18:36:18] fastreid.utils.events INFO:  eta: 7:23:43  epoch/iter: 16/33999  total_loss: 1.67  loss_cls: 1.645  loss_triplet: 0.01733  time: 0.1258  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 18:36:43] fastreid.utils.events INFO:  eta: 7:22:40  epoch/iter: 16/34199  total_loss: 1.754  loss_cls: 1.741  loss_triplet: 0.01421  time: 0.1258  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 18:37:08] fastreid.utils.events INFO:  eta: 7:21:25  epoch/iter: 16/34399  total_loss: 1.746  loss_cls: 1.726  loss_triplet: 0.01616  time: 0.1258  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:37:33] fastreid.utils.events INFO:  eta: 7:20:59  epoch/iter: 16/34599  total_loss: 1.779  loss_cls: 1.756  loss_triplet: 0.01437  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:37:58] fastreid.utils.events INFO:  eta: 7:22:00  epoch/iter: 16/34799  total_loss: 1.785  loss_cls: 1.759  loss_triplet: 0.0162  time: 0.1258  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 18:38:23] fastreid.utils.events INFO:  eta: 7:24:27  epoch/iter: 16/34999  total_loss: 1.787  loss_cls: 1.765  loss_triplet: 0.01536  time: 0.1258  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 18:38:35] fastreid.utils.events INFO:  eta: 7:24:48  epoch/iter: 16/35087  total_loss: 1.788  loss_cls: 1.772  loss_triplet: 0.01536  time: 0.1258  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 18:38:49] fastreid.utils.events INFO:  eta: 7:25:25  epoch/iter: 17/35199  total_loss: 1.808  loss_cls: 1.788  loss_triplet: 0.01465  time: 0.1258  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 18:39:14] fastreid.utils.events INFO:  eta: 7:25:47  epoch/iter: 17/35399  total_loss: 1.766  loss_cls: 1.747  loss_triplet: 0.01679  time: 0.1258  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 18:39:39] fastreid.utils.events INFO:  eta: 7:25:38  epoch/iter: 17/35599  total_loss: 1.733  loss_cls: 1.718  loss_triplet: 0.01605  time: 0.1258  data_time: 0.0015  lr: 3.49e-04  max_mem: 8604M
[04/19 18:40:04] fastreid.utils.events INFO:  eta: 7:24:38  epoch/iter: 17/35799  total_loss: 1.671  loss_cls: 1.648  loss_triplet: 0.01808  time: 0.1258  data_time: 0.0009  lr: 3.49e-04  max_mem: 8604M
[04/19 18:40:29] fastreid.utils.events INFO:  eta: 7:23:41  epoch/iter: 17/35999  total_loss: 1.716  loss_cls: 1.695  loss_triplet: 0.01504  time: 0.1258  data_time: 0.0029  lr: 3.49e-04  max_mem: 8604M
[04/19 18:40:55] fastreid.utils.events INFO:  eta: 7:22:50  epoch/iter: 17/36199  total_loss: 1.735  loss_cls: 1.724  loss_triplet: 0.01484  time: 0.1258  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 18:41:20] fastreid.utils.events INFO:  eta: 7:22:08  epoch/iter: 17/36399  total_loss: 1.742  loss_cls: 1.723  loss_triplet: 0.01364  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:41:45] fastreid.utils.events INFO:  eta: 7:21:31  epoch/iter: 17/36599  total_loss: 1.733  loss_cls: 1.719  loss_triplet: 0.01461  time: 0.1258  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 18:42:10] fastreid.utils.events INFO:  eta: 7:21:38  epoch/iter: 17/36799  total_loss: 1.77  loss_cls: 1.749  loss_triplet: 0.01403  time: 0.1258  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 18:42:35] fastreid.utils.events INFO:  eta: 7:21:01  epoch/iter: 17/36999  total_loss: 1.779  loss_cls: 1.757  loss_triplet: 0.01448  time: 0.1258  data_time: 0.0015  lr: 3.49e-04  max_mem: 8604M
[04/19 18:42:55] fastreid.utils.events INFO:  eta: 7:20:44  epoch/iter: 17/37151  total_loss: 1.783  loss_cls: 1.765  loss_triplet: 0.01404  time: 0.1258  data_time: 0.0039  lr: 3.49e-04  max_mem: 8604M
[04/19 18:43:01] fastreid.utils.events INFO:  eta: 7:20:48  epoch/iter: 18/37199  total_loss: 1.762  loss_cls: 1.744  loss_triplet: 0.01484  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:43:26] fastreid.utils.events INFO:  eta: 7:20:36  epoch/iter: 18/37399  total_loss: 1.789  loss_cls: 1.766  loss_triplet: 0.01658  time: 0.1258  data_time: 0.0008  lr: 3.49e-04  max_mem: 8604M
[04/19 18:43:51] fastreid.utils.events INFO:  eta: 7:20:51  epoch/iter: 18/37599  total_loss: 1.723  loss_cls: 1.707  loss_triplet: 0.01715  time: 0.1258  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 18:44:16] fastreid.utils.events INFO:  eta: 7:20:26  epoch/iter: 18/37799  total_loss: 1.667  loss_cls: 1.645  loss_triplet: 0.01684  time: 0.1258  data_time: 0.0026  lr: 3.49e-04  max_mem: 8604M
[04/19 18:44:41] fastreid.utils.events INFO:  eta: 7:20:25  epoch/iter: 18/37999  total_loss: 1.714  loss_cls: 1.703  loss_triplet: 0.01395  time: 0.1258  data_time: 0.0036  lr: 3.49e-04  max_mem: 8604M
[04/19 18:45:07] fastreid.utils.events INFO:  eta: 7:19:54  epoch/iter: 18/38199  total_loss: 1.739  loss_cls: 1.72  loss_triplet: 0.0145  time: 0.1258  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:45:32] fastreid.utils.events INFO:  eta: 7:20:46  epoch/iter: 18/38399  total_loss: 1.78  loss_cls: 1.756  loss_triplet: 0.01673  time: 0.1258  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 18:45:58] fastreid.utils.events INFO:  eta: 7:21:20  epoch/iter: 18/38599  total_loss: 1.747  loss_cls: 1.734  loss_triplet: 0.01386  time: 0.1258  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 18:46:23] fastreid.utils.events INFO:  eta: 7:20:31  epoch/iter: 18/38799  total_loss: 1.754  loss_cls: 1.738  loss_triplet: 0.01586  time: 0.1258  data_time: 0.0026  lr: 3.49e-04  max_mem: 8604M
[04/19 18:46:48] fastreid.utils.events INFO:  eta: 7:19:15  epoch/iter: 18/38999  total_loss: 1.744  loss_cls: 1.723  loss_triplet: 0.01477  time: 0.1258  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 18:47:14] fastreid.utils.events INFO:  eta: 7:17:59  epoch/iter: 18/39199  total_loss: 1.749  loss_cls: 1.73  loss_triplet: 0.01392  time: 0.1258  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 18:47:16] fastreid.utils.events INFO:  eta: 7:17:50  epoch/iter: 18/39215  total_loss: 1.743  loss_cls: 1.723  loss_triplet: 0.01392  time: 0.1258  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:47:39] fastreid.utils.events INFO:  eta: 7:16:35  epoch/iter: 19/39399  total_loss: 1.736  loss_cls: 1.714  loss_triplet: 0.01512  time: 0.1259  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 18:48:04] fastreid.utils.events INFO:  eta: 7:15:35  epoch/iter: 19/39599  total_loss: 1.638  loss_cls: 1.618  loss_triplet: 0.01536  time: 0.1259  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:48:30] fastreid.utils.events INFO:  eta: 7:15:56  epoch/iter: 19/39799  total_loss: 1.702  loss_cls: 1.69  loss_triplet: 0.01317  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 18:48:55] fastreid.utils.events INFO:  eta: 7:16:24  epoch/iter: 19/39999  total_loss: 1.726  loss_cls: 1.71  loss_triplet: 0.01302  time: 0.1259  data_time: 0.0030  lr: 3.49e-04  max_mem: 8604M
[04/19 18:49:20] fastreid.utils.events INFO:  eta: 7:16:04  epoch/iter: 19/40199  total_loss: 1.728  loss_cls: 1.713  loss_triplet: 0.01459  time: 0.1259  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 18:49:45] fastreid.utils.events INFO:  eta: 7:16:36  epoch/iter: 19/40399  total_loss: 1.736  loss_cls: 1.719  loss_triplet: 0.01221  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 18:50:11] fastreid.utils.events INFO:  eta: 7:16:25  epoch/iter: 19/40599  total_loss: 1.754  loss_cls: 1.736  loss_triplet: 0.01373  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 18:50:36] fastreid.utils.events INFO:  eta: 7:15:38  epoch/iter: 19/40799  total_loss: 1.772  loss_cls: 1.752  loss_triplet: 0.01592  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 18:51:01] fastreid.utils.events INFO:  eta: 7:15:07  epoch/iter: 19/40999  total_loss: 1.759  loss_cls: 1.734  loss_triplet: 0.01644  time: 0.1259  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 18:51:27] fastreid.utils.events INFO:  eta: 7:14:56  epoch/iter: 19/41199  total_loss: 1.729  loss_cls: 1.709  loss_triplet: 0.01467  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:51:37] fastreid.utils.events INFO:  eta: 7:14:16  epoch/iter: 19/41279  total_loss: 1.709  loss_cls: 1.689  loss_triplet: 0.0161  time: 0.1259  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 18:51:52] fastreid.utils.events INFO:  eta: 7:13:34  epoch/iter: 20/41399  total_loss: 1.686  loss_cls: 1.667  loss_triplet: 0.01785  time: 0.1259  data_time: 0.0009  lr: 3.49e-04  max_mem: 8604M
[04/19 18:52:17] fastreid.utils.events INFO:  eta: 7:12:23  epoch/iter: 20/41599  total_loss: 1.675  loss_cls: 1.66  loss_triplet: 0.01542  time: 0.1259  data_time: 0.0026  lr: 3.49e-04  max_mem: 8604M
[04/19 18:52:42] fastreid.utils.events INFO:  eta: 7:11:32  epoch/iter: 20/41799  total_loss: 1.736  loss_cls: 1.72  loss_triplet: 0.01578  time: 0.1259  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 18:53:07] fastreid.utils.events INFO:  eta: 7:10:26  epoch/iter: 20/41999  total_loss: 1.73  loss_cls: 1.712  loss_triplet: 0.01534  time: 0.1259  data_time: 0.0015  lr: 3.49e-04  max_mem: 8604M
[04/19 18:53:32] fastreid.utils.events INFO:  eta: 7:08:44  epoch/iter: 20/42199  total_loss: 1.756  loss_cls: 1.74  loss_triplet: 0.01447  time: 0.1259  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 18:53:57] fastreid.utils.events INFO:  eta: 7:09:02  epoch/iter: 20/42399  total_loss: 1.741  loss_cls: 1.722  loss_triplet: 0.01445  time: 0.1259  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 18:54:22] fastreid.utils.events INFO:  eta: 7:08:20  epoch/iter: 20/42599  total_loss: 1.79  loss_cls: 1.77  loss_triplet: 0.01478  time: 0.1259  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:54:47] fastreid.utils.events INFO:  eta: 7:07:22  epoch/iter: 20/42799  total_loss: 1.756  loss_cls: 1.739  loss_triplet: 0.01616  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 18:55:13] fastreid.utils.events INFO:  eta: 7:07:08  epoch/iter: 20/42999  total_loss: 1.732  loss_cls: 1.715  loss_triplet: 0.01522  time: 0.1259  data_time: 0.0012  lr: 3.49e-04  max_mem: 8604M
[04/19 18:55:38] fastreid.utils.events INFO:  eta: 7:07:22  epoch/iter: 20/43199  total_loss: 1.696  loss_cls: 1.681  loss_triplet: 0.01601  time: 0.1259  data_time: 0.0012  lr: 3.49e-04  max_mem: 8604M
[04/19 18:55:56] fastreid.utils.events INFO:  eta: 7:05:50  epoch/iter: 20/43343  total_loss: 1.649  loss_cls: 1.631  loss_triplet: 0.01482  time: 0.1259  data_time: 0.0008  lr: 3.49e-04  max_mem: 8604M
[04/19 18:56:03] fastreid.utils.events INFO:  eta: 7:06:17  epoch/iter: 21/43399  total_loss: 1.625  loss_cls: 1.612  loss_triplet: 0.01437  time: 0.1259  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 18:56:28] fastreid.utils.events INFO:  eta: 7:05:57  epoch/iter: 21/43599  total_loss: 1.694  loss_cls: 1.677  loss_triplet: 0.01301  time: 0.1259  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 18:56:54] fastreid.utils.events INFO:  eta: 7:07:25  epoch/iter: 21/43799  total_loss: 1.71  loss_cls: 1.692  loss_triplet: 0.01499  time: 0.1259  data_time: 0.0041  lr: 3.49e-04  max_mem: 8604M
[04/19 18:57:19] fastreid.utils.events INFO:  eta: 7:08:31  epoch/iter: 21/43999  total_loss: 1.732  loss_cls: 1.711  loss_triplet: 0.01404  time: 0.1259  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 18:57:45] fastreid.utils.events INFO:  eta: 7:08:50  epoch/iter: 21/44199  total_loss: 1.735  loss_cls: 1.717  loss_triplet: 0.01424  time: 0.1259  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 18:58:10] fastreid.utils.events INFO:  eta: 7:09:08  epoch/iter: 21/44399  total_loss: 1.706  loss_cls: 1.693  loss_triplet: 0.01272  time: 0.1259  data_time: 0.0029  lr: 3.49e-04  max_mem: 8604M
[04/19 18:58:35] fastreid.utils.events INFO:  eta: 7:08:59  epoch/iter: 21/44599  total_loss: 1.75  loss_cls: 1.729  loss_triplet: 0.01412  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 18:59:00] fastreid.utils.events INFO:  eta: 7:06:55  epoch/iter: 21/44799  total_loss: 1.749  loss_cls: 1.726  loss_triplet: 0.01558  time: 0.1259  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 18:59:26] fastreid.utils.events INFO:  eta: 7:06:21  epoch/iter: 21/44999  total_loss: 1.738  loss_cls: 1.715  loss_triplet: 0.01534  time: 0.1259  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 18:59:51] fastreid.utils.events INFO:  eta: 7:05:15  epoch/iter: 21/45199  total_loss: 1.658  loss_cls: 1.639  loss_triplet: 0.01512  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:00:17] fastreid.utils.events INFO:  eta: 7:04:51  epoch/iter: 21/45399  total_loss: 1.683  loss_cls: 1.666  loss_triplet: 0.01463  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:00:18] fastreid.utils.events INFO:  eta: 7:04:53  epoch/iter: 21/45407  total_loss: 1.691  loss_cls: 1.673  loss_triplet: 0.01461  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 19:00:42] fastreid.utils.events INFO:  eta: 7:04:33  epoch/iter: 22/45599  total_loss: 1.706  loss_cls: 1.687  loss_triplet: 0.01249  time: 0.1259  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 19:01:07] fastreid.utils.events INFO:  eta: 7:05:22  epoch/iter: 22/45799  total_loss: 1.715  loss_cls: 1.702  loss_triplet: 0.01422  time: 0.1259  data_time: 0.0039  lr: 3.49e-04  max_mem: 8604M
[04/19 19:01:33] fastreid.utils.events INFO:  eta: 7:04:55  epoch/iter: 22/45999  total_loss: 1.745  loss_cls: 1.717  loss_triplet: 0.01544  time: 0.1259  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 19:01:58] fastreid.utils.events INFO:  eta: 7:04:36  epoch/iter: 22/46199  total_loss: 1.724  loss_cls: 1.71  loss_triplet: 0.01499  time: 0.1259  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 19:02:23] fastreid.utils.events INFO:  eta: 7:04:10  epoch/iter: 22/46399  total_loss: 1.762  loss_cls: 1.74  loss_triplet: 0.01564  time: 0.1259  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 19:02:49] fastreid.utils.events INFO:  eta: 7:03:57  epoch/iter: 22/46599  total_loss: 1.714  loss_cls: 1.697  loss_triplet: 0.01369  time: 0.1259  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 19:03:14] fastreid.utils.events INFO:  eta: 7:03:32  epoch/iter: 22/46799  total_loss: 1.718  loss_cls: 1.701  loss_triplet: 0.01317  time: 0.1259  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 19:03:39] fastreid.utils.events INFO:  eta: 7:02:42  epoch/iter: 22/46999  total_loss: 1.697  loss_cls: 1.674  loss_triplet: 0.01658  time: 0.1259  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 19:04:04] fastreid.utils.events INFO:  eta: 7:02:03  epoch/iter: 22/47199  total_loss: 1.637  loss_cls: 1.619  loss_triplet: 0.01601  time: 0.1259  data_time: 0.0039  lr: 3.49e-04  max_mem: 8604M
[04/19 19:04:30] fastreid.utils.events INFO:  eta: 7:01:37  epoch/iter: 22/47399  total_loss: 1.714  loss_cls: 1.694  loss_triplet: 0.01574  time: 0.1259  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 19:04:39] fastreid.utils.events INFO:  eta: 7:01:30  epoch/iter: 22/47471  total_loss: 1.709  loss_cls: 1.691  loss_triplet: 0.01557  time: 0.1259  data_time: 0.0030  lr: 3.49e-04  max_mem: 8604M
[04/19 19:04:55] fastreid.utils.events INFO:  eta: 7:01:37  epoch/iter: 23/47599  total_loss: 1.714  loss_cls: 1.7  loss_triplet: 0.01467  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 19:05:21] fastreid.utils.events INFO:  eta: 7:01:16  epoch/iter: 23/47799  total_loss: 1.717  loss_cls: 1.7  loss_triplet: 0.014  time: 0.1259  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 19:05:46] fastreid.utils.events INFO:  eta: 7:01:14  epoch/iter: 23/47999  total_loss: 1.716  loss_cls: 1.702  loss_triplet: 0.01406  time: 0.1259  data_time: 0.0029  lr: 3.49e-04  max_mem: 8604M
[04/19 19:06:11] fastreid.utils.events INFO:  eta: 7:01:08  epoch/iter: 23/48199  total_loss: 1.753  loss_cls: 1.738  loss_triplet: 0.01408  time: 0.1259  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 19:06:37] fastreid.utils.events INFO:  eta: 7:01:23  epoch/iter: 23/48399  total_loss: 1.737  loss_cls: 1.723  loss_triplet: 0.01453  time: 0.1260  data_time: 0.0030  lr: 3.49e-04  max_mem: 8604M
[04/19 19:07:02] fastreid.utils.events INFO:  eta: 7:00:08  epoch/iter: 23/48599  total_loss: 1.711  loss_cls: 1.695  loss_triplet: 0.01488  time: 0.1259  data_time: 0.0022  lr: 3.49e-04  max_mem: 8604M
[04/19 19:07:27] fastreid.utils.events INFO:  eta: 6:59:00  epoch/iter: 23/48799  total_loss: 1.681  loss_cls: 1.663  loss_triplet: 0.01406  time: 0.1259  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 19:07:52] fastreid.utils.events INFO:  eta: 6:56:32  epoch/iter: 23/48999  total_loss: 1.621  loss_cls: 1.605  loss_triplet: 0.01452  time: 0.1259  data_time: 0.0006  lr: 3.49e-04  max_mem: 8604M
[04/19 19:08:17] fastreid.utils.events INFO:  eta: 6:54:18  epoch/iter: 23/49199  total_loss: 1.671  loss_cls: 1.656  loss_triplet: 0.01394  time: 0.1259  data_time: 0.0036  lr: 3.49e-04  max_mem: 8604M
[04/19 19:08:42] fastreid.utils.events INFO:  eta: 6:52:45  epoch/iter: 23/49399  total_loss: 1.68  loss_cls: 1.664  loss_triplet: 0.01513  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:08:59] fastreid.utils.events INFO:  eta: 6:52:13  epoch/iter: 23/49535  total_loss: 1.695  loss_cls: 1.672  loss_triplet: 0.01575  time: 0.1259  data_time: 0.0032  lr: 3.49e-04  max_mem: 8604M
[04/19 19:09:07] fastreid.utils.events INFO:  eta: 6:52:15  epoch/iter: 24/49599  total_loss: 1.709  loss_cls: 1.693  loss_triplet: 0.01445  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 19:09:33] fastreid.utils.events INFO:  eta: 6:52:41  epoch/iter: 24/49799  total_loss: 1.699  loss_cls: 1.678  loss_triplet: 0.01319  time: 0.1259  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 19:09:58] fastreid.utils.events INFO:  eta: 6:53:12  epoch/iter: 24/49999  total_loss: 1.701  loss_cls: 1.68  loss_triplet: 0.01396  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:10:23] fastreid.utils.events INFO:  eta: 6:53:06  epoch/iter: 24/50199  total_loss: 1.714  loss_cls: 1.701  loss_triplet: 0.01435  time: 0.1259  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 19:10:48] fastreid.utils.events INFO:  eta: 6:52:39  epoch/iter: 24/50399  total_loss: 1.716  loss_cls: 1.704  loss_triplet: 0.01423  time: 0.1259  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 19:11:13] fastreid.utils.events INFO:  eta: 6:51:28  epoch/iter: 24/50599  total_loss: 1.741  loss_cls: 1.723  loss_triplet: 0.01582  time: 0.1259  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 19:11:38] fastreid.utils.events INFO:  eta: 6:49:15  epoch/iter: 24/50799  total_loss: 1.677  loss_cls: 1.657  loss_triplet: 0.01712  time: 0.1259  data_time: 0.0008  lr: 3.49e-04  max_mem: 8604M
[04/19 19:12:03] fastreid.utils.events INFO:  eta: 6:48:37  epoch/iter: 24/50999  total_loss: 1.633  loss_cls: 1.613  loss_triplet: 0.01596  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:12:28] fastreid.utils.events INFO:  eta: 6:48:11  epoch/iter: 24/51199  total_loss: 1.689  loss_cls: 1.673  loss_triplet: 0.01336  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:12:53] fastreid.utils.events INFO:  eta: 6:47:37  epoch/iter: 24/51399  total_loss: 1.684  loss_cls: 1.667  loss_triplet: 0.01474  time: 0.1259  data_time: 0.0020  lr: 3.49e-04  max_mem: 8604M
[04/19 19:13:18] fastreid.utils.events INFO:  eta: 6:47:01  epoch/iter: 24/51599  total_loss: 1.711  loss_cls: 1.687  loss_triplet: 0.0144  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:13:18] fastreid.utils.events INFO:  eta: 6:47:01  epoch/iter: 24/51599  total_loss: 1.711  loss_cls: 1.687  loss_triplet: 0.0144  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:13:43] fastreid.utils.events INFO:  eta: 6:47:02  epoch/iter: 25/51799  total_loss: 1.7  loss_cls: 1.689  loss_triplet: 0.01314  time: 0.1259  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 19:14:08] fastreid.utils.events INFO:  eta: 6:45:17  epoch/iter: 25/51999  total_loss: 1.728  loss_cls: 1.716  loss_triplet: 0.01556  time: 0.1259  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 19:14:33] fastreid.utils.events INFO:  eta: 6:45:02  epoch/iter: 25/52199  total_loss: 1.716  loss_cls: 1.698  loss_triplet: 0.01539  time: 0.1259  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 19:14:58] fastreid.utils.events INFO:  eta: 6:44:22  epoch/iter: 25/52399  total_loss: 1.692  loss_cls: 1.672  loss_triplet: 0.01311  time: 0.1259  data_time: 0.0015  lr: 3.49e-04  max_mem: 8604M
[04/19 19:15:23] fastreid.utils.events INFO:  eta: 6:43:58  epoch/iter: 25/52599  total_loss: 1.703  loss_cls: 1.679  loss_triplet: 0.01627  time: 0.1259  data_time: 0.0008  lr: 3.49e-04  max_mem: 8604M
[04/19 19:15:48] fastreid.utils.events INFO:  eta: 6:44:20  epoch/iter: 25/52799  total_loss: 1.609  loss_cls: 1.59  loss_triplet: 0.01666  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:16:13] fastreid.utils.events INFO:  eta: 6:46:01  epoch/iter: 25/52999  total_loss: 1.673  loss_cls: 1.658  loss_triplet: 0.01372  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:16:39] fastreid.utils.events INFO:  eta: 6:47:43  epoch/iter: 25/53199  total_loss: 1.702  loss_cls: 1.682  loss_triplet: 0.01395  time: 0.1259  data_time: 0.0009  lr: 3.49e-04  max_mem: 8604M
[04/19 19:17:04] fastreid.utils.events INFO:  eta: 6:49:16  epoch/iter: 25/53399  total_loss: 1.689  loss_cls: 1.673  loss_triplet: 0.01363  time: 0.1259  data_time: 0.0037  lr: 3.49e-04  max_mem: 8604M
[04/19 19:17:30] fastreid.utils.events INFO:  eta: 6:51:10  epoch/iter: 25/53599  total_loss: 1.727  loss_cls: 1.71  loss_triplet: 0.0143  time: 0.1259  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 19:17:38] fastreid.utils.events INFO:  eta: 6:51:43  epoch/iter: 25/53663  total_loss: 1.727  loss_cls: 1.709  loss_triplet: 0.015  time: 0.1259  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 19:17:56] fastreid.utils.events INFO:  eta: 6:51:39  epoch/iter: 26/53799  total_loss: 1.704  loss_cls: 1.685  loss_triplet: 0.01404  time: 0.1259  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 19:18:21] fastreid.utils.events INFO:  eta: 6:51:16  epoch/iter: 26/53999  total_loss: 1.708  loss_cls: 1.68  loss_triplet: 0.01483  time: 0.1259  data_time: 0.0029  lr: 3.49e-04  max_mem: 8604M
[04/19 19:18:46] fastreid.utils.events INFO:  eta: 6:49:58  epoch/iter: 26/54199  total_loss: 1.73  loss_cls: 1.719  loss_triplet: 0.01305  time: 0.1259  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 19:19:11] fastreid.utils.events INFO:  eta: 6:48:02  epoch/iter: 26/54399  total_loss: 1.711  loss_cls: 1.692  loss_triplet: 0.01606  time: 0.1259  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 19:19:36] fastreid.utils.events INFO:  eta: 6:46:08  epoch/iter: 26/54599  total_loss: 1.663  loss_cls: 1.646  loss_triplet: 0.01677  time: 0.1259  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 19:20:02] fastreid.utils.events INFO:  eta: 6:44:58  epoch/iter: 26/54799  total_loss: 1.633  loss_cls: 1.614  loss_triplet: 0.01491  time: 0.1259  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 19:20:27] fastreid.utils.events INFO:  eta: 6:44:27  epoch/iter: 26/54999  total_loss: 1.678  loss_cls: 1.665  loss_triplet: 0.01554  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:20:52] fastreid.utils.events INFO:  eta: 6:44:04  epoch/iter: 26/55199  total_loss: 1.694  loss_cls: 1.678  loss_triplet: 0.0138  time: 0.1259  data_time: 0.0034  lr: 3.49e-04  max_mem: 8604M
[04/19 19:21:18] fastreid.utils.events INFO:  eta: 6:43:57  epoch/iter: 26/55399  total_loss: 1.707  loss_cls: 1.693  loss_triplet: 0.01319  time: 0.1259  data_time: 0.0035  lr: 3.49e-04  max_mem: 8604M
[04/19 19:21:43] fastreid.utils.events INFO:  eta: 6:44:12  epoch/iter: 26/55599  total_loss: 1.704  loss_cls: 1.684  loss_triplet: 0.01438  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:21:59] fastreid.utils.events INFO:  eta: 6:44:03  epoch/iter: 26/55727  total_loss: 1.688  loss_cls: 1.676  loss_triplet: 0.0135  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:22:08] fastreid.utils.events INFO:  eta: 6:43:48  epoch/iter: 27/55799  total_loss: 1.701  loss_cls: 1.682  loss_triplet: 0.01412  time: 0.1259  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 19:22:33] fastreid.utils.events INFO:  eta: 6:42:50  epoch/iter: 27/55999  total_loss: 1.686  loss_cls: 1.67  loss_triplet: 0.0135  time: 0.1259  data_time: 0.0027  lr: 3.49e-04  max_mem: 8604M
[04/19 19:22:58] fastreid.utils.events INFO:  eta: 6:41:57  epoch/iter: 27/56199  total_loss: 1.706  loss_cls: 1.68  loss_triplet: 0.01541  time: 0.1259  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 19:23:23] fastreid.utils.events INFO:  eta: 6:40:41  epoch/iter: 27/56399  total_loss: 1.655  loss_cls: 1.642  loss_triplet: 0.01569  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:23:48] fastreid.utils.events INFO:  eta: 6:39:04  epoch/iter: 27/56599  total_loss: 1.631  loss_cls: 1.608  loss_triplet: 0.01608  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 19:24:14] fastreid.utils.events INFO:  eta: 6:38:44  epoch/iter: 27/56799  total_loss: 1.693  loss_cls: 1.671  loss_triplet: 0.01452  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 19:24:39] fastreid.utils.events INFO:  eta: 6:38:37  epoch/iter: 27/56999  total_loss: 1.689  loss_cls: 1.675  loss_triplet: 0.01291  time: 0.1259  data_time: 0.0033  lr: 3.49e-04  max_mem: 8604M
[04/19 19:25:04] fastreid.utils.events INFO:  eta: 6:38:51  epoch/iter: 27/57199  total_loss: 1.69  loss_cls: 1.68  loss_triplet: 0.01419  time: 0.1259  data_time: 0.0037  lr: 3.49e-04  max_mem: 8604M
[04/19 19:25:29] fastreid.utils.events INFO:  eta: 6:39:11  epoch/iter: 27/57399  total_loss: 1.686  loss_cls: 1.665  loss_triplet: 0.01357  time: 0.1259  data_time: 0.0030  lr: 3.49e-04  max_mem: 8604M
[04/19 19:25:55] fastreid.utils.events INFO:  eta: 6:39:39  epoch/iter: 27/57599  total_loss: 1.714  loss_cls: 1.693  loss_triplet: 0.0153  time: 0.1259  data_time: 0.0026  lr: 3.49e-04  max_mem: 8604M
[04/19 19:26:19] fastreid.utils.events INFO:  eta: 6:39:15  epoch/iter: 27/57791  total_loss: 1.735  loss_cls: 1.718  loss_triplet: 0.0146  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:26:20] fastreid.utils.events INFO:  eta: 6:39:13  epoch/iter: 28/57799  total_loss: 1.734  loss_cls: 1.716  loss_triplet: 0.01455  time: 0.1259  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 19:26:45] fastreid.utils.events INFO:  eta: 6:38:02  epoch/iter: 28/57999  total_loss: 1.693  loss_cls: 1.68  loss_triplet: 0.01555  time: 0.1259  data_time: 0.0021  lr: 3.49e-04  max_mem: 8604M
[04/19 19:27:10] fastreid.utils.events INFO:  eta: 6:37:01  epoch/iter: 28/58199  total_loss: 1.698  loss_cls: 1.677  loss_triplet: 0.01512  time: 0.1259  data_time: 0.0019  lr: 3.49e-04  max_mem: 8604M
[04/19 19:27:35] fastreid.utils.events INFO:  eta: 6:35:14  epoch/iter: 28/58399  total_loss: 1.64  loss_cls: 1.624  loss_triplet: 0.01502  time: 0.1259  data_time: 0.0011  lr: 3.49e-04  max_mem: 8604M
[04/19 19:28:00] fastreid.utils.events INFO:  eta: 6:34:55  epoch/iter: 28/58599  total_loss: 1.648  loss_cls: 1.632  loss_triplet: 0.01521  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:28:25] fastreid.utils.events INFO:  eta: 6:34:42  epoch/iter: 28/58799  total_loss: 1.689  loss_cls: 1.665  loss_triplet: 0.01521  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:28:51] fastreid.utils.events INFO:  eta: 6:35:07  epoch/iter: 28/58999  total_loss: 1.686  loss_cls: 1.662  loss_triplet: 0.01249  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:29:16] fastreid.utils.events INFO:  eta: 6:34:53  epoch/iter: 28/59199  total_loss: 1.684  loss_cls: 1.664  loss_triplet: 0.01467  time: 0.1259  data_time: 0.0029  lr: 3.49e-04  max_mem: 8604M
[04/19 19:29:41] fastreid.utils.events INFO:  eta: 6:35:36  epoch/iter: 28/59399  total_loss: 1.702  loss_cls: 1.679  loss_triplet: 0.01375  time: 0.1259  data_time: 0.0031  lr: 3.49e-04  max_mem: 8604M
[04/19 19:30:06] fastreid.utils.events INFO:  eta: 6:35:29  epoch/iter: 28/59599  total_loss: 1.705  loss_cls: 1.689  loss_triplet: 0.01427  time: 0.1259  data_time: 0.0028  lr: 3.49e-04  max_mem: 8604M
[04/19 19:30:32] fastreid.utils.events INFO:  eta: 6:35:03  epoch/iter: 28/59799  total_loss: 1.705  loss_cls: 1.68  loss_triplet: 0.0142  time: 0.1259  data_time: 0.0024  lr: 3.49e-04  max_mem: 8604M
[04/19 19:30:39] fastreid.utils.events INFO:  eta: 6:34:39  epoch/iter: 28/59855  total_loss: 1.687  loss_cls: 1.671  loss_triplet: 0.01452  time: 0.1259  data_time: 0.0018  lr: 3.49e-04  max_mem: 8604M
[04/19 19:30:57] fastreid.utils.events INFO:  eta: 6:34:07  epoch/iter: 29/59999  total_loss: 1.692  loss_cls: 1.676  loss_triplet: 0.01618  time: 0.1259  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 19:31:22] fastreid.utils.events INFO:  eta: 6:33:56  epoch/iter: 29/60199  total_loss: 1.681  loss_cls: 1.658  loss_triplet: 0.01423  time: 0.1259  data_time: 0.0014  lr: 3.49e-04  max_mem: 8604M
[04/19 19:31:47] fastreid.utils.events INFO:  eta: 6:33:22  epoch/iter: 29/60399  total_loss: 1.632  loss_cls: 1.607  loss_triplet: 0.01504  time: 0.1259  data_time: 0.0029  lr: 3.49e-04  max_mem: 8604M
[04/19 19:32:12] fastreid.utils.events INFO:  eta: 6:32:58  epoch/iter: 29/60599  total_loss: 1.69  loss_cls: 1.668  loss_triplet: 0.01452  time: 0.1259  data_time: 0.0025  lr: 3.49e-04  max_mem: 8604M
[04/19 19:32:38] fastreid.utils.events INFO:  eta: 6:32:46  epoch/iter: 29/60799  total_loss: 1.681  loss_cls: 1.665  loss_triplet: 0.01556  time: 0.1259  data_time: 0.0037  lr: 3.49e-04  max_mem: 8604M
[04/19 19:33:03] fastreid.utils.events INFO:  eta: 6:33:42  epoch/iter: 29/60999  total_loss: 1.692  loss_cls: 1.678  loss_triplet: 0.01247  time: 0.1259  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 19:33:28] fastreid.utils.events INFO:  eta: 6:32:07  epoch/iter: 29/61199  total_loss: 1.654  loss_cls: 1.639  loss_triplet: 0.01317  time: 0.1259  data_time: 0.0016  lr: 3.49e-04  max_mem: 8604M
[04/19 19:33:53] fastreid.utils.events INFO:  eta: 6:31:04  epoch/iter: 29/61399  total_loss: 1.687  loss_cls: 1.675  loss_triplet: 0.0126  time: 0.1259  data_time: 0.0017  lr: 3.49e-04  max_mem: 8604M
[04/19 19:34:19] fastreid.utils.events INFO:  eta: 6:30:49  epoch/iter: 29/61599  total_loss: 1.693  loss_cls: 1.684  loss_triplet: 0.01374  time: 0.1259  data_time: 0.0023  lr: 3.49e-04  max_mem: 8604M
[04/19 19:34:44] fastreid.utils.events INFO:  eta: 6:29:38  epoch/iter: 29/61799  total_loss: 1.716  loss_cls: 1.696  loss_triplet: 0.0154  time: 0.1259  data_time: 0.0013  lr: 3.49e-04  max_mem: 8604M
[04/19 19:34:59] fastreid.engine.defaults INFO: Prepare testing set
[04/19 19:34:59] fastreid.data.datasets.bases INFO: => Loaded AIC24 in csv format: 
| subset   | # ids   | # images   | # cameras   |
|:---------|:--------|:-----------|:------------|
| query    | 0       | 0          | 0           |
| gallery  | 0       | 0          | 0           |
[04/19 19:34:59] fastreid.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/engine/train_loop.py", line 148, in train
    self.after_epoch()
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/engine/train_loop.py", line 182, in after_epoch
    h.after_epoch()
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/engine/hooks.py", line 377, in after_epoch
    self._do_eval()
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/engine/defaults.py", line 303, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/engine/defaults.py", line 432, in test
    data_loader, evaluator = cls.build_evaluator(cfg, dataset_name)
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/engine/defaults.py", line 414, in build_evaluator
    data_loader, num_query = cls.build_test_loader(cfg, dataset_name)
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/engine/defaults.py", line 410, in build_test_loader
    return build_reid_test_loader(cfg, dataset_name=dataset_name)
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/config/config.py", line 265, in wrapped
    return orig_func(**explicit_args)
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/data/build.py", line 155, in build_reid_test_loader
    data_sampler = samplers.InferenceSampler(len(test_set))
  File "/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid/data/samplers/data_sampler.py", line 72, in __init__
    assert size > 0
AssertionError
[04/19 19:34:59] fastreid.engine.hooks INFO: Overall training speed: 61918 iterations in 2:09:57 (0.1259 s / it)
[04/19 19:34:59] fastreid.engine.hooks INFO: Total training time: 2:10:07 (0:00:09 on hooks)
[04/19 19:35:09] fastreid INFO: Rank of current process: 0. World size: 1
[04/19 19:35:09] fastreid INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0]
numpy                   1.23.5
fastreid                1.3 @/WAVE/users2/unix/jkou/PoseTrack/fast-reid/./fastreid
FASTREID_ENV_MODULE     <not set>
PyTorch                 2.0.0+cu118 @/WAVE/users2/unix/jkou/.conda/envs/aic24/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   Tesla V100-PCIE-32GB
CUDA_HOME               /usr/local/cuda
Pillow                  11.1.0
torchvision             0.15.1+cu118 @/WAVE/users2/unix/jkou/.conda/envs/aic24/lib/python3.9/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75, sm_80, sm_86
fvcore                  0.1.5.post20221221
cv2                     4.11.0
----------------------  ----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/19 19:35:09] fastreid INFO: Command line arguments: Namespace(config_file='configs/jk_experiments/agw-R101.yml', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:60003', opts=[])
[04/19 19:35:09] fastreid INFO: Contents of args.config_file=configs/jk_experiments/agw-R101.yml:
_BASE_: ../Base-AGW.yml

MODEL:
  BACKBONE:
    DEPTH: 101x


DATASETS:
  NAMES: ("AIC24",)
  TESTS: ("AIC24",)

OUTPUT_DIR:  logs/jk_experiments/agw-R101

[04/19 19:35:09] fastreid INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 8
  SAMPLER_TRAIN: NaiveIdentitySampler
  SET_WEIGHT: []
DATASETS:
  COMBINEALL: False
  NAMES: ('AIC24',)
  TESTS: ('AIC24',)
INPUT:
  AFFINE:
    ENABLED: False
  AUGMIX:
    ENABLED: False
    PROB: 0.0
  AUTOAUG:
    ENABLED: False
    PROB: 0.0
  CJ:
    BRIGHTNESS: 0.15
    CONTRAST: 0.15
    ENABLED: False
    HUE: 0.1
    PROB: 0.5
    SATURATION: 0.1
  CROP:
    ENABLED: False
    RATIO: [0.75, 1.3333333333333333]
    SCALE: [0.16, 1]
    SIZE: [224, 224]
  FLIP:
    ENABLED: True
    PROB: 0.5
  PADDING:
    ENABLED: True
    MODE: constant
    SIZE: 10
  REA:
    ENABLED: True
    PROB: 0.5
    VALUE: [123.675, 116.28, 103.53]
  RPT:
    ENABLED: False
    PROB: 0.5
  SIZE_TEST: [256, 128]
  SIZE_TRAIN: [256, 128]
KD:
  EMA:
    ENABLED: False
    MOMENTUM: 0.999
  MODEL_CONFIG: []
  MODEL_WEIGHTS: []
MODEL:
  BACKBONE:
    ATT_DROP_RATE: 0.0
    DEPTH: 101x
    DROP_PATH_RATIO: 0.1
    DROP_RATIO: 0.0
    FEAT_DIM: 2048
    LAST_STRIDE: 1
    NAME: build_resnet_backbone
    NORM: BN
    PRETRAIN: True
    PRETRAIN_PATH: 
    SIE_COE: 3.0
    STRIDE_SIZE: (16, 16)
    WITH_IBN: False
    WITH_NL: True
    WITH_SE: False
  DEVICE: cuda
  FREEZE_LAYERS: []
  HEADS:
    CLS_LAYER: Linear
    EMBEDDING_DIM: 0
    MARGIN: 0.0
    NAME: EmbeddingHead
    NECK_FEAT: before
    NORM: BN
    NUM_CLASSES: 0
    POOL_LAYER: GeneralizedMeanPooling
    SCALE: 1
    WITH_BNNECK: True
  LOSSES:
    CE:
      ALPHA: 0.2
      EPSILON: 0.1
      SCALE: 1.0
    CIRCLE:
      GAMMA: 128
      MARGIN: 0.25
      SCALE: 1.0
    COSFACE:
      GAMMA: 128
      MARGIN: 0.25
      SCALE: 1.0
    FL:
      ALPHA: 0.25
      GAMMA: 2
      SCALE: 1.0
    NAME: ('CrossEntropyLoss', 'TripletLoss')
    TRI:
      HARD_MINING: False
      MARGIN: 0.0
      NORM_FEAT: False
      SCALE: 1.0
  META_ARCHITECTURE: Baseline
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.120000000000005, 57.375]
  QUEUE_SIZE: 8192
  WEIGHTS: 
OUTPUT_DIR: logs/jk_experiments/agw-R101
SOLVER:
  AMP:
    ENABLED: True
  BASE_LR: 0.00035
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 30
  CLIP_GRADIENTS:
    CLIP_TYPE: norm
    CLIP_VALUE: 5.0
    ENABLED: False
    NORM_TYPE: 2.0
  DELAY_EPOCHS: 0
  ETA_MIN_LR: 1e-07
  FREEZE_ITERS: 0
  GAMMA: 0.1
  HEADS_LR_FACTOR: 1.0
  IMS_PER_BATCH: 64
  MAX_EPOCH: 120
  MOMENTUM: 0.9
  NESTEROV: False
  OPT: Adam
  SCHED: MultiStepLR
  STEPS: [40, 90]
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0005
  WEIGHT_DECAY_BIAS: 0.0005
  WEIGHT_DECAY_NORM: 0.0005
TEST:
  AQE:
    ALPHA: 3.0
    ENABLED: False
    QE_K: 5
    QE_TIME: 1
  EVAL_PERIOD: 30
  FLIP:
    ENABLED: False
  IMS_PER_BATCH: 128
  METRIC: cosine
  PRECISE_BN:
    DATASET: Market1501
    ENABLED: False
    NUM_ITER: 300
  RERANK:
    ENABLED: False
    K1: 20
    K2: 6
    LAMBDA: 0.3
  ROC:
    ENABLED: False
[04/19 19:35:09] fastreid INFO: Full config saved to /WAVE/users2/unix/jkou/PoseTrack/fast-reid/logs/jk_experiments/agw-R101/config.yaml
[04/19 19:35:09] fastreid.utils.env INFO: Using a generated random seed 10565840
[04/19 19:35:10] fastreid.engine.defaults INFO: Model:
Baseline(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (6): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (7): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (8): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (9): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (10): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (11): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (12): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (13): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (14): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (15): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (16): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (17): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (18): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (19): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (20): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (21): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (22): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (NL_1): ModuleList()
    (NL_2): ModuleList(
      (0-1): 2 x Non_local(
        (g): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 512, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (NL_3): ModuleList(
      (0-8): 9 x Non_local(
        (g): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 1024, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (NL_4): ModuleList()
  )
  (heads): EmbeddingHead(
    (pool_layer): GeneralizedMeanPooling(3.0, output_size=(1, 1))
    (bottleneck): Sequential(
      (0): BatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (cls_layer): Linear(num_classes=0, scale=1, margin=0.0)
  )
)
[04/19 19:35:10] fastreid.utils.checkpoint INFO: Loading checkpoint from logs/jkcv_experiments/agw-R101/model_best.pth
